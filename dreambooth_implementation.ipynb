{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873a559e-9338-433b-abf8-48024e2f49f4",
   "metadata": {},
   "source": [
    "# Dreambooth Implementation Explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e804759c-893a-4adb-bd29-1c4944e00cde",
   "metadata": {},
   "source": [
    "Dreambooth is a fine-tuning technique for text-to-image diffusion models. It adapts a pre-trained model to generate high-quality, personalized images of a specific subject (person, object, or style) using only a few 5-6 images.\n",
    "\n",
    "It is a unique finetuning technique where we use instance images(subject) and regularization images(class-specific images) to finetune the model, where regularization images helps the model to prevent it from overfitting and forget the previous informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e39ccc1e-722f-4d4a-8c79-a3b7ca02ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "from multiprocessing import Value\n",
    "import toml\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "44a01e92-25b1-41bc-a2dd-40416af02897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate.utils import set_seed\n",
    "from diffusers import DDPMScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c842c83f-0318-4ad7-b3f5-1284ff6acd84",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d602607-2fc7-49df-8e34-23aa8631412c",
   "metadata": {},
   "source": [
    "We will load instance images (images of the subject which we need to personalize the model) and regularization images (subject's class images) and they will be indexed based on even and odd, means in even index instance will be retrive and odd the reg images will be retrive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "056f946b-b054-4b24-81b7-721b5d5a44f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pathlib\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((512,512))\n",
    "])\n",
    "\n",
    "\n",
    "class DreamBoothDataset(Dataset):\n",
    "    def __init__(self, data_dir, reg_dir, transforms, tokenizer, instance_prompt, class_prompt):\n",
    "        self.instance_images = self.load_images(data_dir)\n",
    "        self.reg_images = self.load_images(reg_dir)\n",
    "        self.transforms = transforms\n",
    "        self.tokenizer = tokenizer\n",
    "        self.instance_prompt = instance_prompt\n",
    "        self.class_prompt = class_prompt\n",
    "        self._length = max(len(self.reg_images), len(self.instance_images))\n",
    "        \n",
    "\n",
    "    def load_images(self, data_dir):\n",
    "        images = [] \n",
    "        for img_path in tqdm(pathlib.Path(data_dir).glob(\"*\")):\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                images.append(np.array(img))\n",
    "            except UnidentifiedImageError:\n",
    "                print(f\"Error: {img_path} is not a valid image file.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while opening {img_path}: {e}\")\n",
    "        return images\n",
    "\n",
    "    def process_text(self, tokenizer, input_text):\n",
    "        max_length = tokenizer.model_max_length\n",
    "        text_input = tokenizer(\n",
    "        input_text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "        )\n",
    "        return text_input['input_ids']\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx % 2 == 0:\n",
    "            img = self.instance_images[idx % len(self.instance_images)]\n",
    "            input_ids = self.process_text(self.tokenizer, self.instance_prompt)\n",
    "        else:\n",
    "            reg_idx = torch.randint(0, len(self.reg_images), (1,)).item()\n",
    "            img = self.reg_images[reg_idx]\n",
    "            input_ids = self.process_text(self.tokenizer, self.class_prompt)\n",
    "        if self.transforms:\n",
    "            img = transforms(img)\n",
    "        \n",
    "        return img, input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724d1fe-a262-45e5-aa54-e9ea4a2890b3",
   "metadata": {},
   "source": [
    "### Download the SD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "40e47de2-aae2-4ffa-b491-8af3804d207d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 21 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 6743.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "repo_id = \"SG161222/Realistic_Vision_V6.0_B1_noVAE\"\n",
    "local_model_dir = Path(\"./realitic_vision_sd1.5\")\n",
    "model_dir = snapshot_download(repo_id, local_dir=local_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc44dab-ffe7-4461-a302-95be80539e8f",
   "metadata": {},
   "source": [
    "### Define some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "31881165-e320-4b0f-94d8-8da3bac9d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "instance_prompt = \"a photo of a zwx man\"\n",
    "class_prompt = \"a photo of a man\"\n",
    "prior_loss_weight = 1.0\n",
    "instance_dir = './harsh_photos'\n",
    "reg_dir = Path(\"./reg_dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea069b1a-fa2d-4a72-9b1c-7b16742c39b1",
   "metadata": {},
   "source": [
    "### Generate Reglarization Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "af7e9124-5f8f-4b48-8d9b-373db1a5a3f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "num_reg_images = 50\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "if not reg_dir.exists() or len(list(reg_dir.glob(\"*.jpg\"))) < num_reg_images:\n",
    "    pipeline = StableDiffusionPipeline.from_pretrained(model_dir).to(device)\n",
    "    reg_dir.mkdir(exist_ok=True)\n",
    "    for i in range((num_reg_images // batch_size)+1):\n",
    "        if i == (num_reg_images // batch_size):\n",
    "            total += num_reg_images % batch_size\n",
    "            images = pipeline(class_prompt, num_images_per_prompt=num_reg_images % batch_size).images\n",
    "        else:\n",
    "            total += 4\n",
    "            images = pipeline(class_prompt, num_images_per_prompt=batch_size).images\n",
    "\n",
    "        [img.save(f'{reg_dir}/{i}_{j}.jpg') for j, img in enumerate(images)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9189c475-9838-4feb-8733-ca27397e573b",
   "metadata": {},
   "source": [
    "### Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8f85cd71-cf21-473c-8686-ec556c99f498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPTokenizer(name_or_path='realitic_vision_sd1.5/tokenizer', vocab_size=49408, model_max_length=77, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t49406: AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t49407: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tokenizer\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "\n",
    "tokenizer = CLIPTokenizer.from_pretrained(local_model_dir / 'tokenizer')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50baf25c-c8a7-4473-8b74-818bb126f981",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "889428d0-f529-4e2f-a938-855ccb869697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:01, 16.96it/s]\n",
      "50it [00:00, 726.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DreamBoothDataset(instance_dir, reg_dir, transforms, tokenizer, instance_prompt, class_prompt)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e495ca8-1cad-46ad-90a9-b2fa8f742480",
   "metadata": {},
   "source": [
    "### Create Training Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f4ee6376-88e4-427f-b6b9-bff8f28acfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=8  # or use 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4049f8-8d7b-41b0-8985-5def232f6488",
   "metadata": {},
   "source": [
    "### Define Tensor Presicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "39889a66-2b20-40b9-a9c2-7b3fc11562cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adb2668-a8b1-445d-a41f-d67e57822f5b",
   "metadata": {},
   "source": [
    "### Load Text Encoder, Unet And VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "be94f7a4-1327-4c91-993c-0d64c9ce2fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████| 7/7 [00:02<00:00,  2.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(AutoencoderKL(\n",
       "   (encoder): Encoder(\n",
       "     (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (down_blocks): ModuleList(\n",
       "       (0): DownEncoderBlock2D(\n",
       "         (resnets): ModuleList(\n",
       "           (0-1): 2 x ResnetBlock2D(\n",
       "             (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "             (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "             (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (nonlinearity): SiLU()\n",
       "           )\n",
       "         )\n",
       "         (downsamplers): ModuleList(\n",
       "           (0): Downsample2D(\n",
       "             (conv): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): DownEncoderBlock2D(\n",
       "         (resnets): ModuleList(\n",
       "           (0): ResnetBlock2D(\n",
       "             (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "             (conv1): LoRACompatibleConv(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "             (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (nonlinearity): SiLU()\n",
       "             (conv_shortcut): LoRACompatibleConv(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "           )\n",
       "           (1): ResnetBlock2D(\n",
       "             (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "             (conv1): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "             (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (nonlinearity): SiLU()\n",
       "           )\n",
       "         )\n",
       "         (downsamplers): ModuleList(\n",
       "           (0): Downsample2D(\n",
       "             (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): DownEncoderBlock2D(\n",
       "         (resnets): ModuleList(\n",
       "           (0): ResnetBlock2D(\n",
       "             (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "             (conv1): LoRACompatibleConv(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "             (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (nonlinearity): SiLU()\n",
       "             (conv_shortcut): LoRACompatibleConv(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "           )\n",
       "           (1): ResnetBlock2D(\n",
       "             (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "             (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "             (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (nonlinearity): SiLU()\n",
       "           )\n",
       "         )\n",
       "         (downsamplers): ModuleList(\n",
       "           (0): Downsample2D(\n",
       "             (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (3): DownEncoderBlock2D(\n",
       "         (resnets): ModuleList(\n",
       "           (0-1): 2 x ResnetBlock2D(\n",
       "             (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "             (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "             (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (nonlinearity): SiLU()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mid_block): UNetMidBlock2D(\n",
       "       (attentions): ModuleList(\n",
       "         (0): Attention(\n",
       "           (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "           (to_q): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "           (to_k): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "           (to_v): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "           (to_out): ModuleList(\n",
       "             (0): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (resnets): ModuleList(\n",
       "         (0-1): 2 x ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "           (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (conv_norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "     (conv_act): SiLU()\n",
       "     (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   )\n",
       "   (decoder): Decoder(\n",
       "     (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (up_blocks): ModuleList(\n",
       "       (0-1): 2 x UpDecoderBlock2D(\n",
       "         (resnets): ModuleList(\n",
       "           (0-2): 3 x ResnetBlock2D(\n",
       "             (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "             (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "             (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (nonlinearity): SiLU()\n",
       "           )\n",
       "         )\n",
       "         (upsamplers): ModuleList(\n",
       "           (0): Upsample2D(\n",
       "             (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): UpDecoderBlock2D(\n",
       "         (resnets): ModuleList(\n",
       "           (0): ResnetBlock2D(\n",
       "             (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "             (conv1): LoRACompatibleConv(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "             (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (nonlinearity): SiLU()\n",
       "             (conv_shortcut): LoRACompatibleConv(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "           )\n",
       "           (1-2): 2 x ResnetBlock2D(\n",
       "             (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "             (conv1): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "             (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (nonlinearity): SiLU()\n",
       "           )\n",
       "         )\n",
       "         (upsamplers): ModuleList(\n",
       "           (0): Upsample2D(\n",
       "             (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (3): UpDecoderBlock2D(\n",
       "         (resnets): ModuleList(\n",
       "           (0): ResnetBlock2D(\n",
       "             (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "             (conv1): LoRACompatibleConv(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "             (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (nonlinearity): SiLU()\n",
       "             (conv_shortcut): LoRACompatibleConv(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "           )\n",
       "           (1-2): 2 x ResnetBlock2D(\n",
       "             (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "             (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "             (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (nonlinearity): SiLU()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mid_block): UNetMidBlock2D(\n",
       "       (attentions): ModuleList(\n",
       "         (0): Attention(\n",
       "           (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "           (to_q): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "           (to_k): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "           (to_v): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "           (to_out): ModuleList(\n",
       "             (0): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "             (1): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (resnets): ModuleList(\n",
       "         (0-1): 2 x ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "           (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (conv_norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "     (conv_act): SiLU()\n",
       "     (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   )\n",
       "   (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       " ),\n",
       " CLIPTextModel(\n",
       "   (text_model): CLIPTextTransformer(\n",
       "     (embeddings): CLIPTextEmbeddings(\n",
       "       (token_embedding): Embedding(49408, 768)\n",
       "       (position_embedding): Embedding(77, 768)\n",
       "     )\n",
       "     (encoder): CLIPEncoder(\n",
       "       (layers): ModuleList(\n",
       "         (0-11): 12 x CLIPEncoderLayer(\n",
       "           (self_attn): CLIPAttention(\n",
       "             (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (mlp): CLIPMLP(\n",
       "             (activation_fn): QuickGELUActivation()\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           )\n",
       "           (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " UNet2DConditionModel(\n",
       "   (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (time_proj): Timesteps()\n",
       "   (time_embedding): TimestepEmbedding(\n",
       "     (linear_1): LoRACompatibleLinear(in_features=320, out_features=1280, bias=True)\n",
       "     (act): SiLU()\n",
       "     (linear_2): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "   )\n",
       "   (down_blocks): ModuleList(\n",
       "     (0): CrossAttnDownBlock2D(\n",
       "       (attentions): ModuleList(\n",
       "         (0-1): 2 x Transformer2DModel(\n",
       "           (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "           (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "           (transformer_blocks): ModuleList(\n",
       "             (0): BasicTransformerBlock(\n",
       "               (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "               (attn1): Attention(\n",
       "                 (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                 (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                 (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                 (to_out): ModuleList(\n",
       "                   (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "               (attn2): Attention(\n",
       "                 (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                 (to_k): LoRACompatibleLinear(in_features=768, out_features=320, bias=False)\n",
       "                 (to_v): LoRACompatibleLinear(in_features=768, out_features=320, bias=False)\n",
       "                 (to_out): ModuleList(\n",
       "                   (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "               (ff): FeedForward(\n",
       "                 (net): ModuleList(\n",
       "                   (0): GEGLU(\n",
       "                     (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                   )\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                   (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (resnets): ModuleList(\n",
       "         (0-1): 2 x ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "           (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "         )\n",
       "       )\n",
       "       (downsamplers): ModuleList(\n",
       "         (0): Downsample2D(\n",
       "           (conv): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): CrossAttnDownBlock2D(\n",
       "       (attentions): ModuleList(\n",
       "         (0-1): 2 x Transformer2DModel(\n",
       "           (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "           (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "           (transformer_blocks): ModuleList(\n",
       "             (0): BasicTransformerBlock(\n",
       "               (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "               (attn1): Attention(\n",
       "                 (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                 (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                 (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                 (to_out): ModuleList(\n",
       "                   (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "               (attn2): Attention(\n",
       "                 (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                 (to_k): LoRACompatibleLinear(in_features=768, out_features=640, bias=False)\n",
       "                 (to_v): LoRACompatibleLinear(in_features=768, out_features=640, bias=False)\n",
       "                 (to_out): ModuleList(\n",
       "                   (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "               (ff): FeedForward(\n",
       "                 (net): ModuleList(\n",
       "                   (0): GEGLU(\n",
       "                     (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                   )\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                   (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (resnets): ModuleList(\n",
       "         (0): ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "           (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "           (conv_shortcut): LoRACompatibleConv(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "           (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "         )\n",
       "       )\n",
       "       (downsamplers): ModuleList(\n",
       "         (0): Downsample2D(\n",
       "           (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): CrossAttnDownBlock2D(\n",
       "       (attentions): ModuleList(\n",
       "         (0-1): 2 x Transformer2DModel(\n",
       "           (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "           (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "           (transformer_blocks): ModuleList(\n",
       "             (0): BasicTransformerBlock(\n",
       "               (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "               (attn1): Attention(\n",
       "                 (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                 (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                 (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                 (to_out): ModuleList(\n",
       "                   (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "               (attn2): Attention(\n",
       "                 (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                 (to_k): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n",
       "                 (to_v): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n",
       "                 (to_out): ModuleList(\n",
       "                   (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "               (ff): FeedForward(\n",
       "                 (net): ModuleList(\n",
       "                   (0): GEGLU(\n",
       "                     (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                   )\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                   (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (resnets): ModuleList(\n",
       "         (0): ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "           (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "           (conv_shortcut): LoRACompatibleConv(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "           (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "         )\n",
       "       )\n",
       "       (downsamplers): ModuleList(\n",
       "         (0): Downsample2D(\n",
       "           (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): DownBlock2D(\n",
       "       (resnets): ModuleList(\n",
       "         (0-1): 2 x ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "           (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (up_blocks): ModuleList(\n",
       "     (0): UpBlock2D(\n",
       "       (resnets): ModuleList(\n",
       "         (0-2): 3 x ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "           (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "           (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (upsamplers): ModuleList(\n",
       "         (0): Upsample2D(\n",
       "           (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): CrossAttnUpBlock2D(\n",
       "       (attentions): ModuleList(\n",
       "         (0-2): 3 x Transformer2DModel(\n",
       "           (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "           (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "           (transformer_blocks): ModuleList(\n",
       "             (0): BasicTransformerBlock(\n",
       "               (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "               (attn1): Attention(\n",
       "                 (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                 (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                 (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                 (to_out): ModuleList(\n",
       "                   (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "               (attn2): Attention(\n",
       "                 (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                 (to_k): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n",
       "                 (to_v): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n",
       "                 (to_out): ModuleList(\n",
       "                   (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "               (ff): FeedForward(\n",
       "                 (net): ModuleList(\n",
       "                   (0): GEGLU(\n",
       "                     (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                   )\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                   (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (resnets): ModuleList(\n",
       "         (0-1): 2 x ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "           (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "           (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (2): ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "           (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "           (conv_shortcut): LoRACompatibleConv(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (upsamplers): ModuleList(\n",
       "         (0): Upsample2D(\n",
       "           (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): CrossAttnUpBlock2D(\n",
       "       (attentions): ModuleList(\n",
       "         (0-2): 3 x Transformer2DModel(\n",
       "           (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "           (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "           (transformer_blocks): ModuleList(\n",
       "             (0): BasicTransformerBlock(\n",
       "               (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "               (attn1): Attention(\n",
       "                 (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                 (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                 (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                 (to_out): ModuleList(\n",
       "                   (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "               (attn2): Attention(\n",
       "                 (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                 (to_k): LoRACompatibleLinear(in_features=768, out_features=640, bias=False)\n",
       "                 (to_v): LoRACompatibleLinear(in_features=768, out_features=640, bias=False)\n",
       "                 (to_out): ModuleList(\n",
       "                   (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "               (ff): FeedForward(\n",
       "                 (net): ModuleList(\n",
       "                   (0): GEGLU(\n",
       "                     (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                   )\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                   (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (resnets): ModuleList(\n",
       "         (0): ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "           (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "           (conv_shortcut): LoRACompatibleConv(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "           (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "           (conv_shortcut): LoRACompatibleConv(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (2): ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "           (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "           (conv_shortcut): LoRACompatibleConv(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (upsamplers): ModuleList(\n",
       "         (0): Upsample2D(\n",
       "           (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): CrossAttnUpBlock2D(\n",
       "       (attentions): ModuleList(\n",
       "         (0-2): 3 x Transformer2DModel(\n",
       "           (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "           (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "           (transformer_blocks): ModuleList(\n",
       "             (0): BasicTransformerBlock(\n",
       "               (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "               (attn1): Attention(\n",
       "                 (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                 (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                 (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                 (to_out): ModuleList(\n",
       "                   (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "               (attn2): Attention(\n",
       "                 (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                 (to_k): LoRACompatibleLinear(in_features=768, out_features=320, bias=False)\n",
       "                 (to_v): LoRACompatibleLinear(in_features=768, out_features=320, bias=False)\n",
       "                 (to_out): ModuleList(\n",
       "                   (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "               (ff): FeedForward(\n",
       "                 (net): ModuleList(\n",
       "                   (0): GEGLU(\n",
       "                     (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                   )\n",
       "                   (1): Dropout(p=0.0, inplace=False)\n",
       "                   (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (resnets): ModuleList(\n",
       "         (0): ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "           (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "           (conv_shortcut): LoRACompatibleConv(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1-2): 2 x ResnetBlock2D(\n",
       "           (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "           (conv1): LoRACompatibleConv(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "           (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "           (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (nonlinearity): SiLU()\n",
       "           (conv_shortcut): LoRACompatibleConv(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mid_block): UNetMidBlock2DCrossAttn(\n",
       "     (attentions): ModuleList(\n",
       "       (0): Transformer2DModel(\n",
       "         (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "         (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (transformer_blocks): ModuleList(\n",
       "           (0): BasicTransformerBlock(\n",
       "             (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "             (attn1): Attention(\n",
       "               (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "               (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "               (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "               (to_out): ModuleList(\n",
       "                 (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                 (1): Dropout(p=0.0, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "             (attn2): Attention(\n",
       "               (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "               (to_k): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n",
       "               (to_v): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n",
       "               (to_out): ModuleList(\n",
       "                 (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                 (1): Dropout(p=0.0, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "             (ff): FeedForward(\n",
       "               (net): ModuleList(\n",
       "                 (0): GEGLU(\n",
       "                   (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                 )\n",
       "                 (1): Dropout(p=0.0, inplace=False)\n",
       "                 (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "       )\n",
       "     )\n",
       "     (resnets): ModuleList(\n",
       "       (0-1): 2 x ResnetBlock2D(\n",
       "         (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "         (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "         (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "         (dropout): Dropout(p=0.0, inplace=False)\n",
       "         (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (nonlinearity): SiLU()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "   (conv_act): SiLU()\n",
       "   (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       " ))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(local_model_dir).to('cuda')\n",
    "\n",
    "vae = pipe.vae.to(dtype=dtype)\n",
    "text_encoder = pipe.text_encoder.to(dtype=dtype)\n",
    "unet = pipe.unet.to(dtype=dtype)\n",
    "\n",
    "vae, text_encoder, unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2763cb6e-85f0-49b5-9693-f69ccb01b804",
   "metadata": {},
   "source": [
    "#### Weather to train text encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dab3d218-341f-409b-baea-addd7bac03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_encoder = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cd2758df-3ab9-4ed9-b992-3fec5e44fc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPTextModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 768)\n",
       "      (position_embedding): Embedding(77, 768)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.requires_grad_(True)\n",
    "text_encoder.requires_grad_(train_text_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab4767-323b-4696-808f-d82a640c6768",
   "metadata": {},
   "source": [
    "### We don't need to train VAE so make sure it is in eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6258bdeb-cf1c-49c9-9111-fee69a2a396a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoencoderKL(\n",
       "  (encoder): Encoder(\n",
       "    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (down_blocks): ModuleList(\n",
       "      (0): DownEncoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DownEncoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DownEncoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DownEncoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid_block): UNetMidBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Attention(\n",
       "          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (to_q): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "          (to_k): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "          (to_v): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "    (conv_act): SiLU()\n",
       "    (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (up_blocks): ModuleList(\n",
       "      (0-1): 2 x UpDecoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-2): 3 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): Upsample2D(\n",
       "            (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): UpDecoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): Upsample2D(\n",
       "            (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): UpDecoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid_block): UNetMidBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Attention(\n",
       "          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (to_q): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "          (to_k): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "          (to_v): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "    (conv_act): SiLU()\n",
       "    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.requires_grad_(False)\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5ecefcf4-5cd0-47d4-8f0c-37f1cff8b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fdd5ac4b-e700-4ad6-9a88-a505b99d509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = [\n",
    "    {\"params\": list(unet.parameters()), \"lr\": lr },\n",
    "    {\"params\": list(text_encoder.parameters()), \"lr\": lr }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "86d5fefc-cf6d-4a7d-8dd0-a14151dab145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adafactor (\n",
       "Parameter Group 0\n",
       "    beta1: None\n",
       "    clip_threshold: 1.0\n",
       "    decay_rate: -0.8\n",
       "    eps: (1e-30, 0.001)\n",
       "    lr: 0.0001\n",
       "    relative_step: False\n",
       "    scale_parameter: True\n",
       "    warmup_init: False\n",
       "    weight_decay: 0.0\n",
       "\n",
       "Parameter Group 1\n",
       "    beta1: None\n",
       "    clip_threshold: 1.0\n",
       "    decay_rate: -0.8\n",
       "    eps: (1e-30, 0.001)\n",
       "    lr: 0.0001\n",
       "    relative_step: False\n",
       "    scale_parameter: True\n",
       "    warmup_init: False\n",
       "    weight_decay: 0.0\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_type = transformers.optimization.Adafactor\n",
    "optimizer = optimizer_type(trainable_params, lr=lr, relative_step=False)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74af4c4-31cc-497b-afdb-796dbf417fb0",
   "metadata": {},
   "source": [
    "### Initialize Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "be778a42-3c50-435d-847a-1c10e0275229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.lr_scheduler.LambdaLR at 0x70c64b236fb0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.optimization import SchedulerType, TYPE_TO_SCHEDULER_FUNCTION\n",
    "scheduler_type = SchedulerType(\"constant\") # consine, polynomial\n",
    "lr_scheduler = TYPE_TO_SCHEDULER_FUNCTION[scheduler_type](optimizer)\n",
    "lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dd458217-6b06-401d-a90f-f7b3a9f96e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_text_encoder:\n",
    "    training_models = [text_encoder, unet]\n",
    "else:\n",
    "    [unet]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea40c5f-ff0b-441d-9c82-4848091b1af4",
   "metadata": {},
   "source": [
    "### Difine Noise Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8229d7c6-7a79-478d-b25d-c61137783f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scheduler = DDPMScheduler(\n",
    "    beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000, clip_sample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d78dd40-63be-40fd-bc7f-f486e41dd131",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "080dd5f2-3d51-4065-97fc-45af9c76fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_steps = 500\n",
    "total_steps = 0\n",
    "stop = 0\n",
    "min_timestep = 0\n",
    "max_timestep = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f07b731-42fc-4cc0-b0c4-77835dc09a52",
   "metadata": {},
   "source": [
    "### Start Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb79d97-cbca-4718-9377-2dddcd384230",
   "metadata": {},
   "source": [
    "This training loop iterates over batches, processing images and text inputs. It encodes images, adds noise, predicts noise using a UNet, \n",
    "calculates loss, and updates model parameters. The loop continues until a specified number of steps is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0542de9-ca10-4a4c-a42f-457d836a00eb",
   "metadata": {},
   "source": [
    "How the model is learning:\n",
    "\n",
    "a) Image encoding: The VAE encodes input images into a latent space. <br>\n",
    "b) Text conditioning: The text encoder processes the input text, providing context for image generation. <br>\n",
    "c) Noise addition: Random noise is added to the latent representation of the images at a randomly selected timestep. <br>\n",
    "d) Noise prediction: The UNet attempts to predict this added noise, conditioned on the noisy latent, the timestep, and the text encoding.<br>\n",
    "e) Loss calculation: The model's prediction is compared to the actual noise added, using mean squared error loss. <br>\n",
    "f) Backpropagation: The loss is used to update the model parameters, improving its ability to predict noise accurately. <br>\n",
    "\n",
    "Predicting the noise is central to the diffusion model's learning process. By learning to predict the noise that was added, the model learns to denoise the image. This is because if you can predict the noise accurately, you can subtract it from the noisy image to recover the original.\n",
    "\n",
    "After each step the regularization image is applied to make the learning process long and not prevent the model from overfitting which result in better identity preservation of the subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "298309c8-9b74-4cba-914e-4444b7cc272f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has started\n",
      "Step: 1  Loss: 0.2859356105327606\n",
      "Step: 2  Loss: 0.14254876971244812\n",
      "Step: 3  Loss: 0.17556744813919067\n",
      "Step: 4  Loss: 0.3015856146812439\n",
      "Step: 5  Loss: 0.47736552357673645\n",
      "Step: 6  Loss: 0.006030983291566372\n",
      "Step: 7  Loss: 0.30024585127830505\n",
      "Step: 8  Loss: 0.015318508259952068\n",
      "Step: 9  Loss: 0.2885662913322449\n",
      "Step: 10  Loss: 0.174933522939682\n",
      "Step: 11  Loss: 0.20796789228916168\n",
      "Step: 12  Loss: 0.0394824780523777\n",
      "Step: 13  Loss: 0.04179912060499191\n",
      "Step: 14  Loss: 0.13642758131027222\n",
      "Step: 15  Loss: 0.009633347392082214\n",
      "Step: 16  Loss: 0.14913204312324524\n",
      "Step: 17  Loss: 0.1373412311077118\n",
      "Step: 18  Loss: 0.013937128707766533\n",
      "Step: 19  Loss: 0.007134093437343836\n",
      "Step: 20  Loss: 0.3783424198627472\n",
      "Step: 21  Loss: 0.08668725192546844\n",
      "Step: 22  Loss: 0.005828009452670813\n",
      "Step: 23  Loss: 0.01196327619254589\n",
      "Step: 24  Loss: 0.06169142946600914\n",
      "Step: 25  Loss: 0.016028687357902527\n",
      "Step: 26  Loss: 0.15228384733200073\n",
      "Step: 27  Loss: 0.3887144923210144\n",
      "Step: 28  Loss: 0.050753094255924225\n",
      "Step: 29  Loss: 0.00436613941565156\n",
      "Step: 30  Loss: 0.008820765651762486\n",
      "Step: 31  Loss: 0.0036335436161607504\n",
      "Step: 32  Loss: 0.004677599295973778\n",
      "Step: 33  Loss: 0.003417163621634245\n",
      "Step: 34  Loss: 0.17522096633911133\n",
      "Step: 35  Loss: 0.7470516562461853\n",
      "Step: 36  Loss: 0.18985754251480103\n",
      "Step: 37  Loss: 0.024795563891530037\n",
      "Step: 38  Loss: 0.11759214848279953\n",
      "Step: 39  Loss: 0.009994731284677982\n",
      "Step: 40  Loss: 0.03215055912733078\n",
      "Step: 41  Loss: 0.0022076647728681564\n",
      "Step: 42  Loss: 0.031189529225230217\n",
      "Step: 43  Loss: 0.17889201641082764\n",
      "Step: 44  Loss: 0.0963042601943016\n",
      "Step: 45  Loss: 0.0514821857213974\n",
      "Step: 46  Loss: 0.12350030243396759\n",
      "Step: 47  Loss: 0.19545723497867584\n",
      "Step: 48  Loss: 0.04695999622344971\n",
      "Step: 49  Loss: 0.11286398768424988\n",
      "Step: 50  Loss: 0.5981639623641968\n",
      "Training has started\n",
      "Step: 51  Loss: 0.03910258412361145\n",
      "Step: 52  Loss: 0.012014789506793022\n",
      "Step: 53  Loss: 0.04164789989590645\n",
      "Step: 54  Loss: 0.02566295862197876\n",
      "Step: 55  Loss: 0.020839860662817955\n",
      "Step: 56  Loss: 0.5747901201248169\n",
      "Step: 57  Loss: 0.06329266726970673\n",
      "Step: 58  Loss: 0.00494100246578455\n",
      "Step: 59  Loss: 0.15254691243171692\n",
      "Step: 60  Loss: 0.10129311680793762\n",
      "Step: 61  Loss: 0.053695954382419586\n",
      "Step: 62  Loss: 0.08882515132427216\n",
      "Step: 63  Loss: 0.029612382873892784\n",
      "Step: 64  Loss: 0.2016519159078598\n",
      "Step: 65  Loss: 0.05992818623781204\n",
      "Step: 66  Loss: 0.3003787100315094\n",
      "Step: 67  Loss: 0.008007661439478397\n",
      "Step: 68  Loss: 0.016798323020339012\n",
      "Step: 69  Loss: 0.012827355414628983\n",
      "Step: 70  Loss: 0.011531680822372437\n",
      "Step: 71  Loss: 0.010821416042745113\n",
      "Step: 72  Loss: 0.05032173544168472\n",
      "Step: 73  Loss: 0.21752934157848358\n",
      "Step: 74  Loss: 0.1638479083776474\n",
      "Step: 75  Loss: 0.00494777038693428\n",
      "Step: 76  Loss: 0.12993380427360535\n",
      "Step: 77  Loss: 0.2817870080471039\n",
      "Step: 78  Loss: 0.0024795907083898783\n",
      "Step: 79  Loss: 0.22210639715194702\n",
      "Step: 80  Loss: 0.48385268449783325\n",
      "Step: 81  Loss: 0.3256513476371765\n",
      "Step: 82  Loss: 0.09996165335178375\n",
      "Step: 83  Loss: 0.08665948361158371\n",
      "Step: 84  Loss: 0.033121101558208466\n",
      "Step: 85  Loss: 0.13614702224731445\n",
      "Step: 86  Loss: 0.07421232014894485\n",
      "Step: 87  Loss: 0.006612197030335665\n",
      "Step: 88  Loss: 0.13170522451400757\n",
      "Step: 89  Loss: 0.03188005089759827\n",
      "Step: 90  Loss: 0.0339706689119339\n",
      "Step: 91  Loss: 0.01792454905807972\n",
      "Step: 92  Loss: 0.020239651203155518\n",
      "Step: 93  Loss: 0.09250463545322418\n",
      "Step: 94  Loss: 0.034563399851322174\n",
      "Step: 95  Loss: 0.27120864391326904\n",
      "Step: 96  Loss: 0.02492571249604225\n",
      "Step: 97  Loss: 0.02768988162279129\n",
      "Step: 98  Loss: 0.012334359809756279\n",
      "Step: 99  Loss: 0.1757398396730423\n",
      "Step: 100  Loss: 0.023966223001480103\n",
      "Training has started\n",
      "Step: 101  Loss: 0.45973482728004456\n",
      "Step: 102  Loss: 0.005066628102213144\n",
      "Step: 103  Loss: 0.0034461673349142075\n",
      "Step: 104  Loss: 0.0024330224841833115\n",
      "Step: 105  Loss: 0.017411960288882256\n",
      "Step: 106  Loss: 0.17069974541664124\n",
      "Step: 107  Loss: 0.05373803898692131\n",
      "Step: 108  Loss: 0.1991879791021347\n",
      "Step: 109  Loss: 0.025184663012623787\n",
      "Step: 110  Loss: 0.13919642567634583\n",
      "Step: 111  Loss: 0.014788733795285225\n",
      "Step: 112  Loss: 0.07949286699295044\n",
      "Step: 113  Loss: 0.01373935304582119\n",
      "Step: 114  Loss: 0.3779640793800354\n",
      "Step: 115  Loss: 0.05377700924873352\n",
      "Step: 116  Loss: 0.0830300971865654\n",
      "Step: 117  Loss: 0.00841001607477665\n",
      "Step: 118  Loss: 0.18981298804283142\n",
      "Step: 119  Loss: 0.060643520206213\n",
      "Step: 120  Loss: 0.06614933907985687\n",
      "Step: 121  Loss: 0.08303400129079819\n",
      "Step: 122  Loss: 0.08683432638645172\n",
      "Step: 123  Loss: 0.03809873387217522\n",
      "Step: 124  Loss: 0.26547926664352417\n",
      "Step: 125  Loss: 0.18410569429397583\n",
      "Step: 126  Loss: 0.14126932621002197\n",
      "Step: 127  Loss: 0.09815920889377594\n",
      "Step: 128  Loss: 0.005604441277682781\n",
      "Step: 129  Loss: 0.005221075844019651\n",
      "Step: 130  Loss: 0.04150596261024475\n",
      "Step: 131  Loss: 0.19119437038898468\n",
      "Step: 132  Loss: 0.1089162826538086\n",
      "Step: 133  Loss: 0.11002890765666962\n",
      "Step: 134  Loss: 0.005048498045653105\n",
      "Step: 135  Loss: 0.3801414668560028\n",
      "Step: 136  Loss: 0.2750299870967865\n",
      "Step: 137  Loss: 0.029735852032899857\n",
      "Step: 138  Loss: 0.03346068412065506\n",
      "Step: 139  Loss: 0.018616799265146255\n",
      "Step: 140  Loss: 0.07599294930696487\n",
      "Step: 141  Loss: 0.005742472596466541\n",
      "Step: 142  Loss: 0.01770160347223282\n",
      "Step: 143  Loss: 0.1588653326034546\n",
      "Step: 144  Loss: 0.2736247181892395\n",
      "Step: 145  Loss: 0.1137617900967598\n",
      "Step: 146  Loss: 0.0025878287851810455\n",
      "Step: 147  Loss: 0.05883187800645828\n",
      "Step: 148  Loss: 0.11873477697372437\n",
      "Step: 149  Loss: 0.03966325893998146\n",
      "Step: 150  Loss: 0.09279438853263855\n",
      "Training has started\n",
      "Step: 151  Loss: 0.03262626752257347\n",
      "Step: 152  Loss: 0.3706210255622864\n",
      "Step: 153  Loss: 0.03547998517751694\n",
      "Step: 154  Loss: 0.052222203463315964\n",
      "Step: 155  Loss: 0.484525591135025\n",
      "Step: 156  Loss: 0.16923967003822327\n",
      "Step: 157  Loss: 0.6045345664024353\n",
      "Step: 158  Loss: 0.24641722440719604\n",
      "Step: 159  Loss: 0.015821222215890884\n",
      "Step: 160  Loss: 0.02872024103999138\n",
      "Step: 161  Loss: 0.012055227532982826\n",
      "Step: 162  Loss: 0.0029645541217178106\n",
      "Step: 163  Loss: 0.272006630897522\n",
      "Step: 164  Loss: 0.12354341149330139\n",
      "Step: 165  Loss: 0.04463300108909607\n",
      "Step: 166  Loss: 0.07857498526573181\n",
      "Step: 167  Loss: 0.003568850690498948\n",
      "Step: 168  Loss: 0.02253147028386593\n",
      "Step: 169  Loss: 0.0043965601362288\n",
      "Step: 170  Loss: 0.004615374840795994\n",
      "Step: 171  Loss: 0.007731274701654911\n",
      "Step: 172  Loss: 0.055153194814920425\n",
      "Step: 173  Loss: 0.03784613311290741\n",
      "Step: 174  Loss: 0.04765024781227112\n",
      "Step: 175  Loss: 0.002744985045865178\n",
      "Step: 176  Loss: 0.04830773547291756\n",
      "Step: 177  Loss: 0.002707510720938444\n",
      "Step: 178  Loss: 0.046744465827941895\n",
      "Step: 179  Loss: 0.03124181367456913\n",
      "Step: 180  Loss: 0.1714523583650589\n",
      "Step: 181  Loss: 0.02022859826683998\n",
      "Step: 182  Loss: 0.013969491235911846\n",
      "Step: 183  Loss: 0.03331885486841202\n",
      "Step: 184  Loss: 0.035839103162288666\n",
      "Step: 185  Loss: 0.06381916254758835\n",
      "Step: 186  Loss: 0.14190566539764404\n",
      "Step: 187  Loss: 0.20822595059871674\n",
      "Step: 188  Loss: 0.00943115446716547\n",
      "Step: 189  Loss: 0.02821483090519905\n",
      "Step: 190  Loss: 0.001544799655675888\n",
      "Step: 191  Loss: 0.07742565870285034\n",
      "Step: 192  Loss: 0.006957432720810175\n",
      "Step: 193  Loss: 0.20668041706085205\n",
      "Step: 194  Loss: 0.05416351929306984\n",
      "Step: 195  Loss: 0.3885040283203125\n",
      "Step: 196  Loss: 0.003549091052263975\n",
      "Step: 197  Loss: 0.2840498089790344\n",
      "Step: 198  Loss: 0.063787080347538\n",
      "Step: 199  Loss: 0.024529099464416504\n",
      "Step: 200  Loss: 0.08753438293933868\n",
      "Training has started\n",
      "Step: 201  Loss: 0.04736943542957306\n",
      "Step: 202  Loss: 0.30286574363708496\n",
      "Step: 203  Loss: 0.003332347609102726\n",
      "Step: 204  Loss: 0.045714884996414185\n",
      "Step: 205  Loss: 0.3149358630180359\n",
      "Step: 206  Loss: 0.0824517160654068\n",
      "Step: 207  Loss: 0.011757454834878445\n",
      "Step: 208  Loss: 0.002249309094622731\n",
      "Step: 209  Loss: 0.004820231348276138\n",
      "Step: 210  Loss: 0.19591018557548523\n",
      "Step: 211  Loss: 0.022700447589159012\n",
      "Step: 212  Loss: 0.0056740716099739075\n",
      "Step: 213  Loss: 0.11904533207416534\n",
      "Step: 214  Loss: 0.05442661792039871\n",
      "Step: 215  Loss: 0.4352347254753113\n",
      "Step: 216  Loss: 0.4235426187515259\n",
      "Step: 217  Loss: 0.09453106671571732\n",
      "Step: 218  Loss: 0.1947936713695526\n",
      "Step: 219  Loss: 0.13501881062984467\n",
      "Step: 220  Loss: 0.0631902664899826\n",
      "Step: 221  Loss: 0.007407455705106258\n",
      "Step: 222  Loss: 0.09864860028028488\n",
      "Step: 223  Loss: 0.04559055715799332\n",
      "Step: 224  Loss: 0.28389671444892883\n",
      "Step: 225  Loss: 0.03760572895407677\n",
      "Step: 226  Loss: 0.0614958330988884\n",
      "Step: 227  Loss: 0.3759596645832062\n",
      "Step: 228  Loss: 0.08317510783672333\n",
      "Step: 229  Loss: 0.046405941247940063\n",
      "Step: 230  Loss: 0.006748354993760586\n",
      "Step: 231  Loss: 0.07020823657512665\n",
      "Step: 232  Loss: 0.13510598242282867\n",
      "Step: 233  Loss: 0.1318051815032959\n",
      "Step: 234  Loss: 0.0040240841917693615\n",
      "Step: 235  Loss: 0.011040791869163513\n",
      "Step: 236  Loss: 0.004858609288930893\n",
      "Step: 237  Loss: 0.13399285078048706\n",
      "Step: 238  Loss: 0.001549821230582893\n",
      "Step: 239  Loss: 0.015499191358685493\n",
      "Step: 240  Loss: 0.00952928513288498\n",
      "Step: 241  Loss: 0.011905066668987274\n",
      "Step: 242  Loss: 0.005329766310751438\n",
      "Step: 243  Loss: 0.010678188875317574\n",
      "Step: 244  Loss: 0.12745407223701477\n",
      "Step: 245  Loss: 0.0356951579451561\n",
      "Step: 246  Loss: 0.10661923885345459\n",
      "Step: 247  Loss: 0.06143553555011749\n",
      "Step: 248  Loss: 0.06668926775455475\n",
      "Step: 249  Loss: 0.024790436029434204\n",
      "Step: 250  Loss: 0.01588931679725647\n",
      "Training has started\n",
      "Step: 251  Loss: 0.3215462863445282\n",
      "Step: 252  Loss: 0.552415668964386\n",
      "Step: 253  Loss: 0.13951654732227325\n",
      "Step: 254  Loss: 0.08400418609380722\n",
      "Step: 255  Loss: 0.27632617950439453\n",
      "Step: 256  Loss: 0.011274794116616249\n",
      "Step: 257  Loss: 0.00537088792771101\n",
      "Step: 258  Loss: 0.00663195364177227\n",
      "Step: 259  Loss: 0.053581222891807556\n",
      "Step: 260  Loss: 0.00905330665409565\n",
      "Step: 261  Loss: 0.17524930834770203\n",
      "Step: 262  Loss: 0.2790091037750244\n",
      "Step: 263  Loss: 0.37923291325569153\n",
      "Step: 264  Loss: 0.0333414189517498\n",
      "Step: 265  Loss: 0.06178601458668709\n",
      "Step: 266  Loss: 0.1442212462425232\n",
      "Step: 267  Loss: 0.10939659178256989\n",
      "Step: 268  Loss: 0.05296097695827484\n",
      "Step: 269  Loss: 0.1771397441625595\n",
      "Step: 270  Loss: 0.09463612735271454\n",
      "Step: 271  Loss: 0.019825128838419914\n",
      "Step: 272  Loss: 0.03650422394275665\n",
      "Step: 273  Loss: 0.007680815644562244\n",
      "Step: 274  Loss: 0.12899072468280792\n",
      "Step: 275  Loss: 0.029192080721259117\n",
      "Step: 276  Loss: 0.022629758343100548\n",
      "Step: 277  Loss: 0.15582366287708282\n",
      "Step: 278  Loss: 0.1036953255534172\n",
      "Step: 279  Loss: 0.3800174593925476\n",
      "Step: 280  Loss: 0.010593120008707047\n",
      "Step: 281  Loss: 0.0028451255057007074\n",
      "Step: 282  Loss: 0.1243848130106926\n",
      "Step: 283  Loss: 0.00673544779419899\n",
      "Step: 284  Loss: 0.11999911814928055\n",
      "Step: 285  Loss: 0.012041613459587097\n",
      "Step: 286  Loss: 0.001980561763048172\n",
      "Step: 287  Loss: 0.24104776978492737\n",
      "Step: 288  Loss: 0.006928515620529652\n",
      "Step: 289  Loss: 0.14450903236865997\n",
      "Step: 290  Loss: 0.019498810172080994\n",
      "Step: 291  Loss: 0.0069543723948299885\n",
      "Step: 292  Loss: 0.05951092392206192\n",
      "Step: 293  Loss: 0.009418493136763573\n",
      "Step: 294  Loss: 0.09565852582454681\n",
      "Step: 295  Loss: 0.041591301560401917\n",
      "Step: 296  Loss: 0.06368586421012878\n",
      "Step: 297  Loss: 0.06680002808570862\n",
      "Step: 298  Loss: 0.041724201291799545\n",
      "Step: 299  Loss: 0.09487756341695786\n",
      "Step: 300  Loss: 0.06805862486362457\n",
      "Training has started\n",
      "Step: 301  Loss: 0.012546170502901077\n",
      "Step: 302  Loss: 0.19731110334396362\n",
      "Step: 303  Loss: 0.06385957449674606\n",
      "Step: 304  Loss: 0.19444718956947327\n",
      "Step: 305  Loss: 0.061852868646383286\n",
      "Step: 306  Loss: 0.10121595859527588\n",
      "Step: 307  Loss: 0.09224404394626617\n",
      "Step: 308  Loss: 0.05845709890127182\n",
      "Step: 309  Loss: 0.17725318670272827\n",
      "Step: 310  Loss: 0.04665201157331467\n",
      "Step: 311  Loss: 0.020599782466888428\n",
      "Step: 312  Loss: 0.020614445209503174\n",
      "Step: 313  Loss: 0.18667460978031158\n",
      "Step: 314  Loss: 0.11776741594076157\n",
      "Step: 315  Loss: 0.10186856985092163\n",
      "Step: 316  Loss: 0.0040045431815087795\n",
      "Step: 317  Loss: 0.06691011786460876\n",
      "Step: 318  Loss: 0.14711102843284607\n",
      "Step: 319  Loss: 0.0025554527528584003\n",
      "Step: 320  Loss: 0.13346123695373535\n",
      "Step: 321  Loss: 0.020595509558916092\n",
      "Step: 322  Loss: 0.11520524322986603\n",
      "Step: 323  Loss: 0.17738400399684906\n",
      "Step: 324  Loss: 0.31989097595214844\n",
      "Step: 325  Loss: 0.026311194524168968\n",
      "Step: 326  Loss: 0.08574012666940689\n",
      "Step: 327  Loss: 0.037873536348342896\n",
      "Step: 328  Loss: 0.003083665855228901\n",
      "Step: 329  Loss: 0.41924893856048584\n",
      "Step: 330  Loss: 0.12455238401889801\n",
      "Step: 331  Loss: 0.08533717691898346\n",
      "Step: 332  Loss: 0.0038730408996343613\n",
      "Step: 333  Loss: 0.5062215328216553\n",
      "Step: 334  Loss: 0.11953099071979523\n",
      "Step: 335  Loss: 0.21665000915527344\n",
      "Step: 336  Loss: 0.10980455577373505\n",
      "Step: 337  Loss: 0.08097028732299805\n",
      "Step: 338  Loss: 0.12155687063932419\n",
      "Step: 339  Loss: 0.009273603558540344\n",
      "Step: 340  Loss: 0.18207712471485138\n",
      "Step: 341  Loss: 0.0034337365068495274\n",
      "Step: 342  Loss: 0.25014060735702515\n",
      "Step: 343  Loss: 0.002249771263450384\n",
      "Step: 344  Loss: 0.07783946394920349\n",
      "Step: 345  Loss: 0.016699349507689476\n",
      "Step: 346  Loss: 0.06696213781833649\n",
      "Step: 347  Loss: 0.06243283674120903\n",
      "Step: 348  Loss: 0.0028314413502812386\n",
      "Step: 349  Loss: 0.005954360589385033\n",
      "Step: 350  Loss: 0.13698992133140564\n",
      "Training has started\n",
      "Step: 351  Loss: 0.027553226798772812\n",
      "Step: 352  Loss: 0.03485517203807831\n",
      "Step: 353  Loss: 0.017626892775297165\n",
      "Step: 354  Loss: 0.18759840726852417\n",
      "Step: 355  Loss: 0.16744735836982727\n",
      "Step: 356  Loss: 0.11723823845386505\n",
      "Step: 357  Loss: 0.7196755409240723\n",
      "Step: 358  Loss: 0.006666834466159344\n",
      "Step: 359  Loss: 0.13326948881149292\n",
      "Step: 360  Loss: 0.01034892350435257\n",
      "Step: 361  Loss: 0.019125910475850105\n",
      "Step: 362  Loss: 0.0577901154756546\n",
      "Step: 363  Loss: 0.09251488745212555\n",
      "Step: 364  Loss: 0.23719587922096252\n",
      "Step: 365  Loss: 0.012570824474096298\n",
      "Step: 366  Loss: 0.005355991423130035\n",
      "Step: 367  Loss: 0.23165279626846313\n",
      "Step: 368  Loss: 0.0025747609324753284\n",
      "Step: 369  Loss: 0.0019153149332851171\n",
      "Step: 370  Loss: 0.02851172909140587\n",
      "Step: 371  Loss: 0.014733579009771347\n",
      "Step: 372  Loss: 0.0032095913775265217\n",
      "Step: 373  Loss: 0.23043611645698547\n",
      "Step: 374  Loss: 0.019986629486083984\n",
      "Step: 375  Loss: 0.028945278376340866\n",
      "Step: 376  Loss: 0.3171962797641754\n",
      "Step: 377  Loss: 0.028993474319577217\n",
      "Step: 378  Loss: 0.034807782620191574\n",
      "Step: 379  Loss: 0.19264109432697296\n",
      "Step: 380  Loss: 0.2663816213607788\n",
      "Step: 381  Loss: 0.30927443504333496\n",
      "Step: 382  Loss: 0.09942051023244858\n",
      "Step: 383  Loss: 0.10484184324741364\n",
      "Step: 384  Loss: 0.02367643266916275\n",
      "Step: 385  Loss: 0.004331679083406925\n",
      "Step: 386  Loss: 0.0794445276260376\n",
      "Step: 387  Loss: 0.14191532135009766\n",
      "Step: 388  Loss: 0.05834764614701271\n",
      "Step: 389  Loss: 0.00867583230137825\n",
      "Step: 390  Loss: 0.0726296603679657\n",
      "Step: 391  Loss: 0.009548759087920189\n",
      "Step: 392  Loss: 0.058563895523548126\n",
      "Step: 393  Loss: 0.027867522090673447\n",
      "Step: 394  Loss: 0.0126669742166996\n",
      "Step: 395  Loss: 0.04256577044725418\n",
      "Step: 396  Loss: 0.019600510597229004\n",
      "Step: 397  Loss: 0.04868894815444946\n",
      "Step: 398  Loss: 0.051967740058898926\n",
      "Step: 399  Loss: 0.024355251342058182\n",
      "Step: 400  Loss: 0.15734989941120148\n",
      "Training has started\n",
      "Step: 401  Loss: 0.05785970762372017\n",
      "Step: 402  Loss: 0.08189280331134796\n",
      "Step: 403  Loss: 0.05540771409869194\n",
      "Step: 404  Loss: 0.050192058086395264\n",
      "Step: 405  Loss: 0.11143668740987778\n",
      "Step: 406  Loss: 0.02912333607673645\n",
      "Step: 407  Loss: 0.1567186564207077\n",
      "Step: 408  Loss: 0.11324279010295868\n",
      "Step: 409  Loss: 0.05897531658411026\n",
      "Step: 410  Loss: 0.0025035259313881397\n",
      "Step: 411  Loss: 0.024280186742544174\n",
      "Step: 412  Loss: 0.08275790512561798\n",
      "Step: 413  Loss: 0.2618487477302551\n",
      "Step: 414  Loss: 0.38081809878349304\n",
      "Step: 415  Loss: 0.007788731250911951\n",
      "Step: 416  Loss: 0.006046522408723831\n",
      "Step: 417  Loss: 0.07012306898832321\n",
      "Step: 418  Loss: 0.003444999922066927\n",
      "Step: 419  Loss: 0.02430129610002041\n",
      "Step: 420  Loss: 0.11950358748435974\n",
      "Step: 421  Loss: 0.22447669506072998\n",
      "Step: 422  Loss: 0.3924902677536011\n",
      "Step: 423  Loss: 0.09187394380569458\n",
      "Step: 424  Loss: 0.021920692175626755\n",
      "Step: 425  Loss: 0.014821436256170273\n",
      "Step: 426  Loss: 0.024817775934934616\n",
      "Step: 427  Loss: 0.16033504903316498\n",
      "Step: 428  Loss: 0.01236092671751976\n",
      "Step: 429  Loss: 0.004849944729357958\n",
      "Step: 430  Loss: 0.04021238535642624\n",
      "Step: 431  Loss: 0.009090228006243706\n",
      "Step: 432  Loss: 0.2086544930934906\n",
      "Step: 433  Loss: 0.13082018494606018\n",
      "Step: 434  Loss: 0.006795067805796862\n",
      "Step: 435  Loss: 0.311551570892334\n",
      "Step: 436  Loss: 0.008250021375715733\n",
      "Step: 437  Loss: 0.05630503594875336\n",
      "Step: 438  Loss: 0.11528264731168747\n",
      "Step: 439  Loss: 0.010138818062841892\n",
      "Step: 440  Loss: 0.04421145096421242\n",
      "Step: 441  Loss: 0.018726428970694542\n",
      "Step: 442  Loss: 0.02031288668513298\n",
      "Step: 443  Loss: 0.49889621138572693\n",
      "Step: 444  Loss: 0.006943650543689728\n",
      "Step: 445  Loss: 0.0702296793460846\n",
      "Step: 446  Loss: 0.06130197271704674\n",
      "Step: 447  Loss: 0.006453706882894039\n",
      "Step: 448  Loss: 0.2771749496459961\n",
      "Step: 449  Loss: 0.2753976881504059\n",
      "Step: 450  Loss: 0.0038568773306906223\n",
      "Training has started\n",
      "Step: 451  Loss: 0.0987560898065567\n",
      "Step: 452  Loss: 0.03864345699548721\n",
      "Step: 453  Loss: 0.0077039627358317375\n",
      "Step: 454  Loss: 0.09670943021774292\n",
      "Step: 455  Loss: 0.015806887298822403\n",
      "Step: 456  Loss: 0.0029913317412137985\n",
      "Step: 457  Loss: 0.005583446007221937\n",
      "Step: 458  Loss: 0.10079121589660645\n",
      "Step: 459  Loss: 0.0385073758661747\n",
      "Step: 460  Loss: 0.1594446450471878\n",
      "Step: 461  Loss: 0.8073083758354187\n",
      "Step: 462  Loss: 0.007401368580758572\n",
      "Step: 463  Loss: 0.0024519204162061214\n",
      "Step: 464  Loss: 0.28390800952911377\n",
      "Step: 465  Loss: 0.0517101064324379\n",
      "Step: 466  Loss: 0.1311376690864563\n",
      "Step: 467  Loss: 0.005254814401268959\n",
      "Step: 468  Loss: 0.2550129294395447\n",
      "Step: 469  Loss: 0.03557116910815239\n",
      "Step: 470  Loss: 0.10785412788391113\n",
      "Step: 471  Loss: 0.002036500256508589\n",
      "Step: 472  Loss: 0.02442079409956932\n",
      "Step: 473  Loss: 0.05910741910338402\n",
      "Step: 474  Loss: 0.10065867751836777\n",
      "Step: 475  Loss: 0.033348917961120605\n",
      "Step: 476  Loss: 0.0055586835369467735\n",
      "Step: 477  Loss: 0.10262273997068405\n",
      "Step: 478  Loss: 0.004125028848648071\n",
      "Step: 479  Loss: 0.0023885448463261127\n",
      "Step: 480  Loss: 0.2860502004623413\n",
      "Step: 481  Loss: 0.01673797518014908\n",
      "Step: 482  Loss: 0.004899973515421152\n",
      "Step: 483  Loss: 0.5931663513183594\n",
      "Step: 484  Loss: 0.041779015213251114\n",
      "Step: 485  Loss: 0.31649506092071533\n",
      "Step: 486  Loss: 0.002014709636569023\n",
      "Step: 487  Loss: 0.13817937672138214\n",
      "Step: 488  Loss: 0.0053327567875385284\n",
      "Step: 489  Loss: 0.10814854502677917\n",
      "Step: 490  Loss: 0.00959038082510233\n",
      "Step: 491  Loss: 0.16079114377498627\n",
      "Step: 492  Loss: 0.00946838315576315\n",
      "Step: 493  Loss: 0.21483875811100006\n",
      "Step: 494  Loss: 0.04195703566074371\n",
      "Step: 495  Loss: 0.0032828093972057104\n",
      "Step: 496  Loss: 0.271504670381546\n",
      "Step: 497  Loss: 0.3044685125350952\n",
      "Step: 498  Loss: 0.3086940050125122\n",
      "Step: 499  Loss: 0.04702378809452057\n",
      "Step: 500  Loss: 0.013627899810671806\n"
     ]
    }
   ],
   "source": [
    "while stop == 0:\n",
    "    print(\"Training has started\")\n",
    "\n",
    "    # set the train mode in all trainable models\n",
    "    for model in training_models:\n",
    "        model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        images = batch[0].to(device).to(dtype=dtype)\n",
    "        input_ids = batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            # extract the low dim latents from the vae\n",
    "            latents = vae.encode(images).latent_dist.sample()\n",
    "            latents = latents * 0.18215\n",
    "\n",
    "        batch_size = latents.shape[0]\n",
    "        \n",
    "        # get the text embedding for conditioning\n",
    "        input_ids = input_ids.reshape((-1, tokenizer.model_max_length))\n",
    "        encoder_hidden_states = text_encoder(input_ids)[0]\n",
    "\n",
    "        # sample a random timestep for each image, add noise to the latents\n",
    "        # generate random noise\n",
    "        noise = torch.randn_like(latents, device=latents.device)\n",
    "        # generate random timestep \n",
    "        timesteps = torch.randint(min_timestep, max_timestep, (batch_size,), device=device)\n",
    "        # apply noise to latents\n",
    "        noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "        # run the unet\n",
    "        noise_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
    "        target = noise\n",
    "\n",
    "\n",
    "        # calculate loss, we are using l2 loss\n",
    "        loss = torch.nn.functional.mse_loss(noise_pred.float(), target.float(), reduction=\"none\")\n",
    "        loss = loss.mean([1,2,3])\n",
    "\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "\n",
    "        # apply gradient norm to provent gradient from explording or vanishing\n",
    "        torch.nn.utils.clip_grad_norm_(unet.parameters(), max_norm=1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(text_encoder.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "\n",
    "        total_steps += 1\n",
    "        print(f\"Step: {total_steps}  Loss: {loss.item()}\")\n",
    "        if total_steps >= num_training_steps:\n",
    "            stop = 1\n",
    "            break\n",
    "\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fcaed570-a836-4eda-9900-fc4d7dcf5cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "pipeline = StableDiffusionPipeline(\n",
    "    text_encoder=text_encoder,\n",
    "    vae=vae,\n",
    "    unet=unet,\n",
    "    tokenizer=tokenizer,\n",
    "    scheduler=noise_scheduler,\n",
    "    safety_checker=None,\n",
    "    feature_extractor=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64ae8c-1604-4d17-811a-cc9b259ce07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████▉           | 45/50 [00:01<00:00, 28.31it/s]"
     ]
    }
   ],
   "source": [
    "pipeline(\"potrait of a zwx man in beach\").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c009e6-e661-4910-9c35-8f86a6823fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ffff54-a86e-443d-bd96-f3416218644b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
